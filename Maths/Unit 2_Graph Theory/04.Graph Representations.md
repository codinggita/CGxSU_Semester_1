# Graph Representations

## Learning Objectives

- Understand different methods for representing graphs in computer memory
- Master adjacency matrix representation and its properties
- Work with adjacency list representation for sparse graphs
- Understand incidence matrix representation
- Analyze space and time complexity trade-offs among representations
- Choose appropriate representation based on graph properties and algorithms
- Convert between different representations
- Implement graph operations using each representation

## Prerequisites

- Basic graph theory definitions (vertices, edges, directed/undirected)
- Matrix operations and notation
- Big-O notation and complexity analysis
- Basic data structures (arrays, linked lists)

## Definitions and Theoretical Foundations

### Definition 5.1 (Graph Representation)

A **graph representation** is a data structure that stores the vertices and edges of a graph in computer memory, enabling efficient querying and manipulation.

### Definition 5.2 (Adjacency Matrix)

For a graph $G = (V, E)$ with $n = |V|$ vertices labeled $v_1, v_2, \ldots, v_n$, the **adjacency matrix** is an $n \times n$ matrix $A = [a_{ij}]$ where:

$$a_{ij} = \begin{cases}
1 & \text{if } \{v_i, v_j\} \in E \text{ (undirected)} \\
1 & \text{if } (v_i, v_j) \in E \text{ (directed)} \\
0 & \text{otherwise}
\end{cases}$$

**For weighted graphs:** $a_{ij} = w(\{v_i, v_j\})$ if the edge exists, or $0$ (or $\infty$ for shortest path algorithms) otherwise.

**Properties:**
- **Undirected graphs:** The matrix is **symmetric** ($a_{ij} = a_{ji}$)
- **Directed graphs:** The matrix may be asymmetric
- **Space complexity:** $\Theta(n^2)$ regardless of number of edges
- **Self-loops:** $a_{ii} = 1$ if vertex $i$ has a self-loop

### Theorem 5.1 (Degree from Adjacency Matrix)

For an undirected graph with adjacency matrix $A$:
$$\deg(v_i) = \sum_{j=1}^{n} a_{ij}$$

For a directed graph:
$$\deg^{+}(v_i) = \sum_{j=1}^{n} a_{ij} \quad \text{(out-degree)}$$
$$\deg^{-}(v_i) = \sum_{j=1}^{n} a_{ji} \quad \text{(in-degree)}$$

### Theorem 5.2 (Walks and Matrix Powers)

The entry $a_{ij}^{(k)}$ in $A^k$ (the $k$-th power of adjacency matrix $A$) equals the number of walks of length $k$ from vertex $i$ to vertex $j$.

**Proof Sketch:** By induction on $k$. Base case $k = 1$ is the definition. For $k+1$, use matrix multiplication:
$$(A^{k+1})_{ij} = \sum_{\ell=1}^{n} a_{i\ell} \cdot a_{\ell j}^{(k)}$$
Each term counts walks through intermediate vertex $\ell$. $\square$

### Definition 5.3 (Adjacency List)

An **adjacency list** representation stores for each vertex a list of its adjacent vertices.

For graph $G = (V, E)$ with vertices $v_1, \ldots, v_n$:
- Maintain an array of $n$ lists
- List $i$ contains all vertices $v_j$ such that $\{v_i, v_j\} \in E$ (undirected) or $(v_i, v_j) \in E$ (directed)

**Space complexity:** $\Theta(n + m)$ where $m = |E|$

**For weighted graphs:** Each list entry stores both the adjacent vertex and the edge weight.

### Definition 5.4 (Incidence Matrix)

For a graph $G = (V, E)$ with $n$ vertices and $m$ edges, the **incidence matrix** is an $n \times m$ matrix $M = [m_{ij}]$ where:

**Undirected graph:**
$$m_{ij} = \begin{cases}
1 & \text{if vertex } i \text{ is incident to edge } j \\
0 & \text{otherwise}
\end{cases}$$

**Directed graph:**
$$m_{ij} = \begin{cases}
-1 & \text{if edge } j \text{ leaves vertex } i \\
+1 & \text{if edge } j \text{ enters vertex } i \\
0 & \text{otherwise}
\end{cases}$$

**Space complexity:** $\Theta(nm)$

### Theorem 5.3 (Incidence Matrix Column Sum)

In the incidence matrix of an undirected graph, each column sums to 2 (each edge connects two vertices).

In the incidence matrix of a directed graph, each column sums to 0 (one $-1$ and one $+1$).

### Comparison of Representations

| Operation | Adjacency Matrix | Adjacency List | Incidence Matrix |
|-----------|-----------------|----------------|------------------|
| **Space** | $\Theta(n^2)$ | $\Theta(n + m)$ | $\Theta(nm)$ |
| **Check if edge $(u,v)$ exists** | $\Theta(1)$ | $\Theta(\deg(u))$ | $\Theta(m)$ |
| **Find all neighbors of $u$** | $\Theta(n)$ | $\Theta(\deg(u))$ | $\Theta(m)$ |
| **Add edge** | $\Theta(1)$ | $\Theta(1)$ | $\Theta(1)$ |
| **Remove edge** | $\Theta(1)$ | $\Theta(\deg(u))$ | $\Theta(m)$ |
| **Iterate over all edges** | $\Theta(n^2)$ | $\Theta(n + m)$ | $\Theta(nm)$ |

**Best use cases:**
- **Adjacency matrix:** Dense graphs, need fast edge existence checks, matrix operations
- **Adjacency list:** Sparse graphs, need to iterate over neighbors
- **Incidence matrix:** Theoretical analysis, specific algorithms (e.g., flow networks)

## Worked Examples

### Example 1 (Simple): Constructing Adjacency Matrix

**Problem:** Construct the adjacency matrix for the undirected graph with vertices $\{A, B, C, D\}$ and edges $\{\{A,B\}, \{B,C\}, \{C,D\}, \{D,A\}\}$.

**Solution:**

Order vertices: $A = 1, B = 2, C = 3, D = 4$.

Construct matrix:

$$A = \begin{bmatrix}
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0
\end{bmatrix}$$

Verify symmetry: $a_{ij} = a_{ji}$ for all $i, j$. ✓ $\square$

---

### Example 2 (Intermediate): Adjacency List for Directed Graph

**Problem:** Create the adjacency list for the directed graph with edges: $A \to B$, $A \to C$, $B \to D$, $C \to D$.

**Solution:**

```
A: [B, C]
B: [D]
C: [D]
D: []
```

**Analysis:**
- Out-degree of $A$ = 2, $B$ = 1, $C$ = 1, $D$ = 0
- Space used: 4 list headers + 4 edge entries = $\Theta(n + m) = \Theta(4 + 4) = \Theta(8)$ $\square$

---

### Example 3 (Intermediate): Incidence Matrix

**Problem:** Construct the incidence matrix for the undirected graph from Example 1.

**Solution:**

Edges: $e_1 = \{A,B\}$, $e_2 = \{B,C\}$, $e_3 = \{C,D\}$, $e_4 = \{D,A\}$

$$M = \begin{bmatrix}
1 & 0 & 0 & 1 \\
1 & 1 & 0 & 0 \\
0 & 1 & 1 & 0 \\
0 & 0 & 1 & 1
\end{bmatrix}$$

Each column has exactly two 1s (each edge connects two vertices). ✓ $\square$

---

### Example 4 (Challenging): Counting Walks

**Problem:** Using the adjacency matrix from Example 1, find the number of walks of length 2 from vertex $A$ to vertex $C$.

**Solution:**

Compute $A^2$:

$$A^2 = \begin{bmatrix}
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0
\end{bmatrix}
\begin{bmatrix}
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0
\end{bmatrix}$$

Computing entry $(1,3)$ (row $A$, column $C$):
$$(A^2)_{13} = 0 \cdot 0 + 1 \cdot 1 + 0 \cdot 0 + 1 \cdot 1 = 2$$

**Verification:** Walks of length 2 from $A$ to $C$:
1. $A \to B \to C$
2. $A \to D \to C$

Indeed, 2 walks. ✓ $\square$

---

### Example 5 (Challenging): Space Complexity Analysis

**Problem:** A social network has 1 million users. On average, each user has 150 friends. Compare the storage requirements for adjacency matrix vs. adjacency list.

**Solution:**

Let $n = 10^6$ users, average degree $\bar{d} = 150$.

Total edges (undirected): $m \approx \frac{n \bar{d}}{2} = \frac{10^6 \cdot 150}{2} = 75 \times 10^6$

**Adjacency matrix:**
- Storage: $n^2 = (10^6)^2 = 10^{12}$ bits (assuming 1 bit per entry)
- With 1 byte per entry: $10^{12}$ bytes = 1 TB (terabyte)

**Adjacency list:**
- Storage: $\Theta(n + m) = 10^6 + 75 \times 10^6 = 76 \times 10^6$ entries
- With 4 bytes per pointer: $76 \times 10^6 \times 4 = 304 \times 10^6$ bytes ≈ 304 MB

**Conclusion:** Adjacency list uses about $\frac{304 \text{ MB}}{1000 \text{ GB}} \approx 0.03\%$ of the space required by adjacency matrix.

For sparse graphs (social networks), adjacency lists are far superior. $\square$

---

### Example 6 (Advanced): Converting Representations

**Problem:** Given an adjacency list, write an algorithm to construct the adjacency matrix.

**Solution:**

**Algorithm:**
```
Input: Adjacency list L for n vertices
Output: n × n adjacency matrix A

1. Initialize A as n × n matrix of zeros
2. For each vertex i from 1 to n:
      For each vertex j in L[i]:
          A[i][j] = 1
3. Return A
```

**Time complexity:** $\Theta(n + m)$ to scan the adjacency list + $\Theta(n^2)$ to initialize matrix = $\Theta(n^2)$

**Space complexity:** $\Theta(n^2)$ for the matrix. $\square$

## Applications and Intuition

### Sparse vs. Dense Graphs

**Sparse graph** ($m \ll n^2$): Adjacency list saves space.
- Example: Social networks, web graphs, road networks

**Dense graph** ($m \approx n^2$): Adjacency matrix is comparable or better.
- Example: Complete graphs, small dense clusters

### Algorithm Choice

**Breadth-First Search (BFS):**
- Adjacency list: $\Theta(n + m)$
- Adjacency matrix: $\Theta(n^2)$
- **Preference:** Adjacency list for sparse graphs

**Floyd-Warshall (All-Pairs Shortest Paths):**
- Naturally uses adjacency matrix
- Time: $\Theta(n^3)$

**Graph Powers and Walks:**
- Adjacency matrix allows matrix multiplication
- Useful for connectivity, reachability analysis

### Practical Considerations

**Adjacency matrix:**
- Simple implementation
- Cache-friendly for small graphs
- Easy parallelization

**Adjacency list:**
- Dynamic graphs (frequent edge additions/deletions)
- Large sparse graphs
- Saves memory

## Exercises

### Exercise 1

Construct the adjacency matrix for the complete graph $K_4$.

**Hint:** All vertices are connected to all others.

**Solution:**
$$A = \begin{bmatrix}
0 & 1 & 1 & 1 \\
1 & 0 & 1 & 1 \\
1 & 1 & 0 & 1 \\
1 & 1 & 1 & 0
\end{bmatrix}$$

---

### Exercise 2

For the directed graph with edges $1 \to 2, 2 \to 3, 3 \to 1$, find the adjacency matrix and verify that the trace (sum of diagonal elements) equals the number of self-loops.

**Solution:**
$$A = \begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix}$$

Trace = $0 + 0 + 0 = 0$. No self-loops. ✓

---

### Exercise 3

A graph has adjacency list:
```
1: [2, 3]
2: [1, 3, 4]
3: [1, 2]
4: [2]
```
How many edges does the graph have?

**Hint:** Count total entries and divide by 2 (undirected).

**Solution:**
Total entries = $2 + 3 + 2 + 1 = 8$.

Edges = $8 / 2 = 4$.

---

### Exercise 4

For a graph with $n$ vertices and $m$ edges represented as an adjacency matrix, what is the time complexity to count the total number of edges?

**Hint:** Scan the entire matrix.

**Solution:**
Must check all $n^2$ entries. Time = $\Theta(n^2)$.

---

### Exercise 5

Prove that for an undirected graph, the sum of all entries in the adjacency matrix equals $2m$ where $m$ is the number of edges.

**Hint:** Each edge contributes to two entries.

**Solution:**
Each edge $\{i, j\}$ contributes 1 to $a_{ij}$ and 1 to $a_{ji}$.

Total sum = $2m$. $\square$

---

### Exercise 6 (Challenge)

Design a data structure that supports:
- Check if edge $(u, v)$ exists: $O(1)$
- Iterate over neighbors of $u$: $O(\deg(u))$
- Space: $O(n + m)$

**Hint:** Combine adjacency list with a hash table or additional pointers.

**Solution:**
Use an **adjacency list** with an auxiliary **hash set** for each vertex storing its neighbors.

- Edge existence: Check hash set in $O(1)$ expected time
- Iterate neighbors: Traverse adjacency list in $O(\deg(u))$
- Space: Adjacency list $O(n + m)$ + hash sets $O(n + m) = O(n + m)$ $\square$

---

### Exercise 7 (Challenge)

For a directed acyclic graph (DAG), the adjacency matrix can be made upper triangular by topological sorting. Prove this claim.

**Hint:** In a topological order, all edges go from earlier to later vertices.

**Solution:**
A topological sort orders vertices such that for every edge $(u, v)$, $u$ comes before $v$.

Relabel vertices according to topological order: $v_1, v_2, \ldots, v_n$.

Then for every edge $(v_i, v_j)$, we have $i < j$.

In the adjacency matrix, $a_{ij} = 1$ only if $i < j$, making it upper triangular. $\square$

## Common Mistakes and Misconceptions

1. **Assuming adjacency matrix is always preferable:** For sparse graphs, it wastes enormous space.

2. **Forgetting symmetry in undirected graphs:** Always set both $a_{ij}$ and $a_{ji}$ when adding an edge.

3. **Mixing up directed/undirected incidence matrices:** Sign convention differs.

4. **Ignoring space complexity:** For large graphs (millions of vertices), $n^2$ storage is infeasible.

5. **Time complexity of neighbor iteration:** In adjacency matrix, finding neighbors requires scanning an entire row ($\Theta(n)$), not just the neighbors.

## Summary and Key Takeaways

1. **Adjacency matrix:** $n \times n$ matrix, $\Theta(n^2)$ space, $O(1)$ edge checks, $O(n)$ neighbor listing.

2. **Adjacency list:** Array of lists, $\Theta(n + m)$ space, $O(\deg(u))$ edge checks and neighbor listing.

3. **Incidence matrix:** $n \times m$ matrix, $\Theta(nm)$ space, less commonly used in practice.

4. **Sparse graphs:** Use adjacency lists for memory efficiency.

5. **Dense graphs:** Adjacency matrices can be competitive and simpler.

6. **Matrix powers:** Adjacency matrix raised to power $k$ counts walks of length $k$.

7. **Algorithm design:** Choice of representation affects time/space complexity of graph algorithms.

---

**Further Study:** Explore compressed sparse row (CSR) format, edge list representations, and advanced data structures like dynamic trees and link-cut trees.
