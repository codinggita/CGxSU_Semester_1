# Expectation, Variance, and Standard Deviation

## Learning Objectives

- Define expectation (mean) for discrete and continuous random variables
- Master properties of expectation including linearity
- Define and calculate variance and standard deviation
- Apply computational formulas for variance
- Understand relationships between these measures
- Solve problems involving expected value and variance

## Prerequisites

- Random variables (discrete and continuous)
- Probability mass functions and density functions
- Basic calculus and summation notation

## Definitions and Theoretical Foundations

### Definition 5.1 (Expectation - Discrete Case)

For a discrete random variable $X$ with PMF $p_X(x)$, the **expectation** (or **mean**) is:

$$E[X] = \sum_{\text{all } x} x \cdot p_X(x)$$

provided the sum converges absolutely.

**Notation:** $E[X]$, $\mu$, or $\mu_X$

### Definition 5.2 (Expectation - Continuous Case)

For a continuous random variable $X$ with PDF $f_X(x)$, the **expectation** is:

$$E[X] = \int_{-\infty}^{\infty} x \cdot f_X(x) \, dx$$

provided the integral converges absolutely.

### Theorem 5.1 (Linearity of Expectation)

For random variables $X$ and $Y$ and constants $a, b, c$:

$$E[aX + bY + c] = aE[X] + bE[Y] + c$$

**Proof for discrete case:**

$$E[aX + bY + c] = \sum_{x,y} (ax + by + c) p_{X,Y}(x,y)$$
$$= a\sum_{x,y} x \cdot p_{X,Y}(x,y) + b\sum_{x,y} y \cdot p_{X,Y}(x,y) + c\sum_{x,y} p_{X,Y}(x,y)$$
$$= aE[X] + bE[Y] + c$$ $\square$

**Important:** This holds whether or not $X$ and $Y$ are independent!

### Theorem 5.2 (Expectation of a Function)

For a function $g:\mathbb{R} \to \mathbb{R}$:

**Discrete:** $E[g(X)] = \sum_x g(x) p_X(x)$

**Continuous:** $E[g(X)] = \int_{-\infty}^{\infty} g(x) f_X(x) \, dx$

### Definition 5.3 (Variance)

The **variance** of a random variable $X$ is:

$$\text{Var}(X) = E[(X - \mu)^2]$$

where $\mu = E[X]$.

**Notation:** $\text{Var}(X)$, $\sigma^2$, or $\sigma_X^2$

**Interpretation:** Variance measures the average squared deviation from the mean; it quantifies spread or dispersion.

### Theorem 5.3 (Computational Formula for Variance)

$$\text{Var}(X) = E[X^2] - (E[X])^2$$

**Proof:**

$$\text{Var}(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
$$= E[X^2] - 2\mu E[X] + \mu^2$$
$$= E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2$$ $\square$

### Theorem 5.4 (Properties of Variance)

For constants $a$ and $b$:

1. $\text{Var}(aX + b) = a^2 \text{Var}(X)$
2. $\text{Var}(X) \geq 0$ with equality iff $X$ is constant
3. If $X$ and $Y$ are independent: $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$

**Proof of (1):**

$$\text{Var}(aX + b) = E[(aX + b - E[aX + b])^2]$$
$$= E[(aX + b - a\mu - b)^2] = E[a^2(X - \mu)^2]$$
$$= a^2 E[(X - \mu)^2] = a^2 \text{Var}(X)$$ $\square$

### Definition 5.4 (Standard Deviation)

The **standard deviation** of $X$ is:

$$\sigma = \sqrt{\text{Var}(X)}$$

**Interpretation:** Standard deviation measures spread in the same units as $X$.

## Worked Examples

### Example 1 (Simple): Fair Die

**Problem:** Let $X$ be the result of rolling a fair die. Find $E[X]$, $\text{Var}(X)$, and $\sigma$.

**Solution:**

PMF: $p_X(x) = \frac{1}{6}$ for $x \in \{1, 2, 3, 4, 5, 6\}$

**Expectation:**
$$E[X] = \sum_{x=1}^{6} x \cdot \frac{1}{6} = \frac{1}{6}(1+2+3+4+5+6) = \frac{21}{6} = 3.5$$

**Second moment:**
$$E[X^2] = \sum_{x=1}^{6} x^2 \cdot \frac{1}{6} = \frac{1}{6}(1+4+9+16+25+36) = \frac{91}{6}$$

**Variance:**
$$\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{182 - 147}{12} = \frac{35}{12} \approx 2.917$$

**Standard deviation:**
$$\sigma = \sqrt{\frac{35}{12}} \approx 1.708$$

**Answers:** $E[X] = 3.5$, $\text{Var}(X) = \frac{35}{12}$, $\sigma \approx 1.71$ $\square$

---

### Example 2 (Intermediate): Custom Distribution

**Problem:** Let $X$ have PMF: $p_X(1) = 0.2$, $p_X(2) = 0.5$, $p_X(3) = 0.3$. Find $E[X]$, $\text{Var}(X)$, and $E[3X - 2]$.

**Solution:**

**Expectation:**
$$E[X] = 1(0.2) + 2(0.5) + 3(0.3) = 0.2 + 1.0 + 0.9 = 2.1$$

**Second moment:**
$$E[X^2] = 1^2(0.2) + 2^2(0.5) + 3^2(0.3) = 0.2 + 2.0 + 2.7 = 4.9$$

**Variance:**
$$\text{Var}(X) = E[X^2] - (E[X])^2 = 4.9 - (2.1)^2 = 4.9 - 4.41 = 0.49$$

**Using linearity:**
$$E[3X - 2] = 3E[X] - 2 = 3(2.1) - 2 = 4.3$$

**Answers:** $E[X] = 2.1$, $\text{Var}(X) = 0.49$, $E[3X-2] = 4.3$ $\square$

---

### Example 3 (Intermediate): Uniform Continuous

**Problem:** Let $X \sim \text{Uniform}[0, 1]$ with PDF $f_X(x) = 1$ for $0 \leq x \leq 1$. Find $E[X]$ and $\text{Var}(X)$.

**Solution:**

**Expectation:**
$$E[X] = \int_0^1 x \cdot 1 \, dx = \left[\frac{x^2}{2}\right]_0^1 = \frac{1}{2}$$

**Second moment:**
$$E[X^2] = \int_0^1 x^2 \cdot 1 \, dx = \left[\frac{x^3}{3}\right]_0^1 = \frac{1}{3}$$

**Variance:**
$$\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{1}{3} - \left(\frac{1}{2}\right)^2 = \frac{1}{3} - \frac{1}{4} = \frac{1}{12}$$

**General formula for Uniform$[a,b]$:**
- $E[X] = \frac{a+b}{2}$
- $\text{Var}(X) = \frac{(b-a)^2}{12}$

**Answers:** $E[X] = \frac{1}{2}$, $\text{Var}(X) = \frac{1}{12}$ $\square$

---

### Example 4 (Challenging): Variance Properties

**Problem:** Let $X$ have $E[X] = 10$ and $\text{Var}(X) = 4$. Find:
(a) $E[2X + 5]$
(b) $\text{Var}(2X + 5)$
(c) $E[(X-10)^2]$

**Solution:**

**(a)** Using linearity:
$$E[2X + 5] = 2E[X] + 5 = 2(10) + 5 = 25$$

**(b)** Using variance property:
$$\text{Var}(2X + 5) = 2^2 \text{Var}(X) = 4(4) = 16$$

**(c)** By definition of variance with $\mu = 10$:
$$E[(X-10)^2] = E[(X - E[X])^2] = \text{Var}(X) = 4$$

**Answers:** (a) 25, (b) 16, (c) 4 $\square$

---

### Example 5 (Challenging): Exponential Distribution

**Problem:** Let $X$ have PDF $f_X(x) = \lambda e^{-\lambda x}$ for $x \geq 0$. Find $E[X]$ and $\text{Var}(X)$.

**Solution:**

**Expectation:** Using integration by parts with $u = x$, $dv = \lambda e^{-\lambda x} dx$:
$$E[X] = \int_0^{\infty} x \lambda e^{-\lambda x} \, dx$$
$$= \left[-xe^{-\lambda x}\right]_0^{\infty} + \int_0^{\infty} e^{-\lambda x} \, dx$$
$$= 0 + \left[-\frac{1}{\lambda}e^{-\lambda x}\right]_0^{\infty} = \frac{1}{\lambda}$$

**Second moment:** Using integration by parts twice:
$$E[X^2] = \int_0^{\infty} x^2 \lambda e^{-\lambda x} \, dx = \frac{2}{\lambda^2}$$

**Variance:**
$$\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}$$

**Answers:** $E[X] = \frac{1}{\lambda}$, $\text{Var}(X) = \frac{1}{\lambda^2}$ $\square$

## Exercises

### Exercise 1

Let $X$ have PMF: $p_X(-1) = 0.3$, $p_X(0) = 0.4$, $p_X(1) = 0.3$. Find $E[X]$ and $\text{Var}(X)$.

**Hint:** Notice the symmetry; $E[X] = 0$ immediately.

**Solution:**
$E[X] = -1(0.3) + 0(0.4) + 1(0.3) = 0$
$E[X^2] = 1(0.3) + 0(0.4) + 1(0.3) = 0.6$
$\text{Var}(X) = 0.6 - 0 = 0.6$ ✓

---

### Exercise 2

If $E[X] = 5$ and $E[X^2] = 30$, find $\text{Var}(X)$ and the standard deviation.

**Hint:** Use the computational formula directly.

**Solution:**
$\text{Var}(X) = E[X^2] - (E[X])^2 = 30 - 25 = 5$
$\sigma = \sqrt{5} \approx 2.236$ ✓

---

### Exercise 3

Let $X \sim \text{Uniform}[2, 8]$. Find $E[X]$ and $\text{Var}(X)$.

**Hint:** Use formulas: $E[X] = \frac{a+b}{2}$, $\text{Var}(X) = \frac{(b-a)^2}{12}$.

**Solution:**
$E[X] = \frac{2+8}{2} = 5$
$\text{Var}(X) = \frac{(8-2)^2}{12} = \frac{36}{12} = 3$ ✓

---

### Exercise 4

If $\text{Var}(X) = 9$, find $\text{Var}(3X - 7)$.

**Hint:** Use $\text{Var}(aX + b) = a^2\text{Var}(X)$.

**Solution:** $\text{Var}(3X - 7) = 3^2 \cdot 9 = 81$ ✓

---

### Exercise 5

Prove that $\text{Var}(X) = 0$ if and only if $P(X = c) = 1$ for some constant $c$.

**Hint:** Use the fact that $\text{Var}(X) = E[(X - \mu)^2] \geq 0$.

**Solution:** $\text{Var}(X) = 0 \Rightarrow E[(X-\mu)^2] = 0$. Since $(X-\mu)^2 \geq 0$ always, this means $(X-\mu)^2 = 0$ with probability 1, so $X = \mu$ with probability 1. ✓

## Applications

### Finance
Expected return and variance (risk) are fundamental in portfolio theory and asset pricing.

### Quality Control
Process mean and variance track manufacturing consistency.

### Machine Learning
Feature normalization uses mean and standard deviation to standardize data.

### Insurance
Expected claims and variance determine premiums and reserves.

## Common Mistakes

1. **Confusing $E[X^2]$ and $(E[X])^2$:** These are generally different! Always use $\text{Var}(X) = E[X^2] - (E[X])^2$.

2. **Linearity of variance:** $\text{Var}(X+Y) \neq \text{Var}(X) + \text{Var}(Y)$ in general (only when independent).

3. **Units:** Variance has squared units; use standard deviation for original units.

4. **Non-linearity with constants:** $\text{Var}(aX + b) = a^2\text{Var}(X)$, not $a\text{Var}(X)$.

## Summary

1. **Expectation** $E[X]$ measures central tendency (weighted average)

2. **Linearity:** $E[aX + bY + c] = aE[X] + bE[Y] + c$ (always holds)

3. **Variance** $\text{Var}(X) = E[(X-\mu)^2] = E[X^2] - (E[X])^2$ measures spread

4. **Standard deviation** $\sigma = \sqrt{\text{Var}(X)}$ in original units

5. **Key formulas:**
   - $\text{Var}(aX + b) = a^2\text{Var}(X)$
   - If independent: $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$

---

**Further Study:** Moments, moment generating functions, covariance and correlation, Chebyshev's inequality.
