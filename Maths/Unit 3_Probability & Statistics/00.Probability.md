# Foundations of Probability

## Learning Objectives

- Understand the axiomatic foundation of probability theory
- Master sample spaces, events, and probability measures
- Apply probability axioms to solve problems
- Distinguish between different types of events
- Calculate probabilities using counting principles
- Understand the relationship between probability and set theory

## Prerequisites

- Set theory (unions, intersections, complements)
- Basic counting principles and combinatorics
- Understanding of fractions and ratios
- Logical reasoning

## Definitions and Theoretical Foundations

### Definition 1.1 (Probability)

**Probability** is a mathematical framework for quantifying uncertainty. It assigns a numerical measure to the likelihood of events occurring in random experiments.

### Definition 1.2 (Random Experiment)

A **random experiment** is a process or procedure that:
1. Can be repeated under identical conditions
2. Has a well-defined set of possible outcomes
3. The outcome cannot be predicted with certainty before execution

**Examples:** Tossing a coin, rolling a die, drawing a card from a deck.

### Definition 1.3 (Sample Space)

The **sample space** $S$ (or $\Omega$) of a random experiment is the set of all possible outcomes.

**Notation:** $S = \{\omega_1, \omega_2, \ldots, \omega_n\}$ for finite sample spaces.

**Examples:**
- Coin toss: $S = \{H, T\}$
- Die roll: $S = \{1, 2, 3, 4, 5, 6\}$
- Two coin tosses: $S = \{HH, HT, TH, TT\}$

### Definition 1.4 (Event)

An **event** $E$ is a subset of the sample space $S$, i.e., $E \subseteq S$.

**Types of Events:**
- **Simple (Elementary) Event:** Contains exactly one outcome, $|E| = 1$
- **Compound Event:** Contains multiple outcomes, $|E| > 1$
- **Certain Event:** $E = S$, always occurs
- **Impossible Event:** $E = \emptyset$, never occurs

**Examples:**
- $E_1 = \{2, 4, 6\}$ (rolling an even number on a die)
- $E_2 = \{3\}$ (rolling exactly 3)
- $E_3 = S$ (rolling any number from 1 to 6)

### Definition 1.5 (Mutually Exclusive Events)

Two events $A$ and $B$ are **mutually exclusive** (or **disjoint**) if they cannot occur simultaneously:
$$A \cap B = \emptyset$$

**Example:** When rolling a die, events $A = \{2, 4, 6\}$ (even) and $B = \{1, 3, 5\}$ (odd) are mutually exclusive.

### Definition 1.6 (Exhaustive Events)

Events $E_1, E_2, \ldots, E_n$ are **exhaustive** if their union equals the sample space:
$$E_1 \cup E_2 \cup \cdots \cup E_n = S$$

### Definition 1.7 (Complement of an Event)

The **complement** of event $E$, denoted $E^c$ or $\overline{E}$ or $E'$, is the set of all outcomes in $S$ that are not in $E$:
$$E^c = S \setminus E = \{s \in S : s \notin E\}$$

**Property:** $E \cup E^c = S$ and $E \cap E^c = \emptyset$

## Axioms of Probability (Kolmogorov Axioms)

### Axiom 1 (Non-Negativity)

For any event $E$:
$$P(E) \geq 0$$

The probability of an event is never negative.

### Axiom 2 (Normalization)

The probability of the entire sample space is 1:
$$P(S) = 1$$

### Axiom 3 (Countable Additivity)

For any countable sequence of mutually exclusive events $E_1, E_2, E_3, \ldots$:
$$P\left(\bigcup_{i=1}^{\infty} E_i\right) = \sum_{i=1}^{\infty} P(E_i)$$

For finite collections, if $E_1, E_2, \ldots, E_n$ are pairwise disjoint:
$$P(E_1 \cup E_2 \cup \cdots \cup E_n) = P(E_1) + P(E_2) + \cdots + P(E_n)$$

## Theorems and Properties

### Theorem 1.1 (Complement Rule)

For any event $E$:
$$P(E^c) = 1 - P(E)$$

**Proof:**

Since $E$ and $E^c$ are disjoint and $E \cup E^c = S$:

$$P(E \cup E^c) = P(E) + P(E^c) = P(S) = 1$$

Therefore:
$$P(E^c) = 1 - P(E)$$ $\square$

### Theorem 1.2 (Probability of Impossible Event)

$$P(\emptyset) = 0$$

**Proof:**

Let $E = \emptyset$. Then $E^c = S$.

By the Complement Rule:
$$P(\emptyset) = 1 - P(S) = 1 - 1 = 0$$ $\square$

### Theorem 1.3 (Monotonicity)

If $A \subseteq B$, then $P(A) \leq P(B)$.

**Proof:**

We can write $B = A \cup (B \setminus A)$, where $A$ and $B \setminus A$ are disjoint.

By Axiom 3:
$$P(B) = P(A) + P(B \setminus A)$$

Since $P(B \setminus A) \geq 0$ by Axiom 1:
$$P(B) \geq P(A)$$ $\square$

### Theorem 1.4 (General Addition Rule)

For any two events $A$ and $B$:
$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$

**Proof:**

We can partition $A \cup B$ into three disjoint parts:
- $A \setminus B$ (elements in $A$ only)
- $B \setminus A$ (elements in $B$ only)
- $A \cap B$ (elements in both)

Then:
$$P(A \cup B) = P(A \setminus B) + P(A \cap B) + P(B \setminus A)$$

Also:
$$P(A) = P(A \setminus B) + P(A \cap B)$$
$$P(B) = P(B \setminus A) + P(A \cap B)$$

Adding these:
$$P(A) + P(B) = P(A \setminus B) + 2P(A \cap B) + P(B \setminus A)$$

Therefore:
$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$ $\square$

### Theorem 1.5 (Bounded Probability)

For any event $E$:
$$0 \leq P(E) \leq 1$$

**Proof:**

From Axiom 1: $P(E) \geq 0$ ✓

Since $E \subseteq S$, by Theorem 1.3: $P(E) \leq P(S) = 1$ ✓ $\square$

## Classical (Laplace) Probability

### Definition definitions 1.8 (Equally Likely Outcomes)

Outcomes in a sample space are **equally likely** if each has the same probability of occurring.

### Theorem 1.6 (Classical Probability Formula)

For a finite sample space $S$ with equally likely outcomes:

$$P(E) = \frac{|E|}{|S|} = \frac{\text{Number of favorable outcomes}}{\text{Total number of possible outcomes}}$$

where $|E|$ denotes the cardinality (number of elements) of set $E$.

## Worked Examples

### Example 1 (Simple): Coin Toss

**Problem:** A fair coin is tossed once. Find the probability of getting heads.

**Solution:**

Sample space: $S = \{H, T\}$, $|S| = 2$

Event: $E = \{H\}$, $|E| = 1$

Since the coin is fair, outcomes are equally likely:

$$P(H) = \frac{|E|}{|S|} = \frac{1}{2}$$

**Answer:** $P(H) = 0.5$ or $50\%$ $\square$

---

### Example 2 (Simple): Die Roll

**Problem:** A fair six-sided die is rolled. Find the probability of rolling an even number.

**Solution:**

Sample space: $S = \{1, 2, 3, 4, 5, 6\}$, $|S| = 6$

Event (even number): $E = \{2, 4, 6\}$, $|E| = 3$

$$P(E) = \frac{3}{6} = \frac{1}{2}$$

**Answer:** $P(\text{even}) = \frac{1}{2}$ $\square$

---

### Example 3 (Intermediate): Card Drawing

**Problem:** One card is drawn from a standard 52-card deck. Find:
(a) $P(\text{King})$
(b) $P(\text{Red card})$
(c) $P(\text{Red King})$

**Solution:**

Sample space: $|S| = 52$

**(a)** Event: 4 Kings in deck

$$P(\text{King}) = \frac{4}{52} = \frac{1}{13}$$

**(b)** Event: 26 red cards (13 hearts + 13 diamonds)

$$P(\text{Red}) = \frac{26}{52} = \frac{1}{2}$$

**(c)** Event: 2 red Kings (King of Hearts, King of Diamonds)

$$P(\text{Red King}) = \frac{2}{52} = \frac{1}{26}$$ $\square$

---

### Example 4 (Intermediate): Complement Rule Application

**Problem:** The probability that it rains tomorrow is 0.3. What is the probability that it does not rain?

**Solution:**

Let $R$ = event "it rains tomorrow"

Given: $P(R) = 0.3$

By Complement Rule:
$$P(R^c) = 1 - P(R) = 1 - 0.3 = 0.7$$

**Answer:** $P(\text{no rain}) = 0.7$ or $70\%$ $\square$

---

### Example 5 (Challenging): Two Dice

**Problem:** Two fair dice are rolled. Find the probability that the sum is at least 10.

**Solution:**

**Sample space:** $|S| = 6 \times 6 = 36$ (ordered pairs)

**Event:** $E = \{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\}$

Breakdown:
- Sum = 10: $(4,6), (5,5), (6,4)$ → 3 outcomes
- Sum = 11: $(5,6), (6,5)$ → 2 outcomes
- Sum = 12: $(6,6)$ → 1 outcome

Total: $|E| = 6$

$$P(E) = \frac{6}{36} = \frac{1}{6}$$

**Answer:** $P(\text{sum} \geq 10) = \frac{1}{6} \approx 0.167$ $\square$

---

### Example 6 (Challenging): Addition Rule

**Problem:** In a class of 100 students, 60 study Math, 50 study Physics, and 30 study both. If a student is selected at random, find the probability that they study Math or Physics.

**Solution:**

Let $M$ = event "studies Math", $P$ = event "studies Physics"

Given:
- $P(M) = \frac{60}{100} = 0.6$
- $P(P) = \frac{50}{100} = 0.5$
- $P(M \cap P) = \frac{30}{100} = 0.3$

By the General Addition Rule:
$$P(M \cup P) = P(M) + P(P) - P(M \cap P)$$
$$= 0.6 + 0.5 - 0.3 = 0.8$$

**Answer:** $P(\text{Math or Physics}) = 0.8$ or $80\%$ $\square$

## Exercises

### Exercise 1

A bag contains 5 red balls and 3 blue balls. One ball is drawn at random. Find $P(\text{red})$.

**Solution:** $P(\text{red}) = \frac{5}{8}$ ✓

---

### Exercise 2

Two coins are tossed. Find the probability of getting at least one head.

**Hint:** Use the complement.

**Solution:**

$S = \{HH, HT, TH, TT\}$, $|S| = 4$

Complement: $P(\text{no heads}) = P(TT) = \frac{1}{4}$

$$P(\text{at least one H}) = 1 - \frac{1}{4} = \frac{3}{4}$$ ✓

---

### Exercise 3

Prove that $P(A \cap B^c) = P(A) - P(A \cap B)$.

**Solution:**

$A = (A \cap B) \cup (A \cap B^c)$ (disjoint union)

By Axiom 3:
$$P(A) = P(A \cap B) + P(A \cap B^c)$$

Therefore:
$$P(A \cap B^c) = P(A) - P(A \cap B)$$ $\square$

---

### Exercise 4

If $P(A) = 0.7$, $P(B) = 0.5$, and $P(A \cap B) = 0.3$, find $P(A^c \cap B^c)$.

**Hint:** Use De Morgan's Law: $(A \cup B)^c = A^c \cap B^c$

**Solution:**

$$P(A \cup B) = 0.7 + 0.5 - 0.3 = 0.9$$
$$P(A^c \cap B^c) = P((A \cup B)^c) = 1 - 0.9 = 0.1$$ ✓

---

### Exercise 5

Show that if $A \subseteq B$, then $P(B \setminus A) = P(B) - P(A)$.

**Solution:**

$B = A \cup (B \setminus A)$ (disjoint)

$$P(B) = P(A) + P(B \setminus A)$$
$$P(B \setminus A) = P(B) - P(A)$$ $\square$

## Applications

**Statistics:** Foundation for statistical inference and hypothesis testing

**Machine Learning:** Probabilistic models, Bayesian inference, classification

**Finance:** Risk assessment, option pricing, portfolio optimization

**Engineering:** Reliability analysis, quality control, signal processing

**Data Science:** A/B testing, predictive modeling, decision trees

## Common Mistakes

1. **Assuming equally likely outcomes when they're not:** Always verify uniformity
2. **Confusing $P(A \cup B)$ with $P(A) + P(B)$:** Must subtract $P(A \cap B)$
3. **Forgetting the complement:** Often easier to compute $1 - P(E^c)$
4. **Confusing "and" with "or":** $\cap$ vs. $\cup$ in probability statements
5. **Not checking axioms:** Ensure $0 \leq P(E) \leq 1$ for all events

## Summary

1. **Probability** quantifies uncertainty using a mathematical framework
2. **Sample space $S$** contains all possible outcomes of a random experiment
3. **Events** are subsets of the sample space
4. **Kolmogorov Axioms** provide the formal foundation:
   - Non-negativity: $P(E) \geq 0$
   - Normalization: $P(S) = 1$
   - Additivity: $P(E_1 \cup E_2) = P(E_1) + P(E_2)$ for disjoint events
5. **Key formulas:**
   - Classical: $P(E) = \frac{|E|}{|S|}$ (equally likely outcomes)
   - Complement: $P(E^c) = 1 - P(E)$
   - Addition: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$

---

**Further Study:** Conditional probability, independence, random variables, probability distributions.
