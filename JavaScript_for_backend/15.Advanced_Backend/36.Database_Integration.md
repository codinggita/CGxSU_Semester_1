# Database Integration in Node.js

**Difficulty:** Intermediate to Advanced
**Estimated Time:** 90-120 minutes
**Prerequisites:** Node.js fundamentals, async/await, REST APIs, SQL basics
**Target:** Node.js 18+ LTS, PostgreSQL 14+, MongoDB 6+

---

## Learning Objectives

By the end of this lesson, you will be able to:

1. Understand the fundamental differences between SQL and NoSQL databases
2. Connect Node.js applications to MongoDB using Mongoose
3. Connect Node.js applications to PostgreSQL using pg and Sequelize
4. Implement CRUD operations in both MongoDB and PostgreSQL
5. Build complex queries using query builders and ORMs
6. Manage database transactions for data integrity
7. Implement connection pooling for optimal performance
8. Choose between ORMs and query builders based on requirements
9. Handle database errors and implement retry logic
10. Apply database best practices in production applications

---

## Table of Contents

1. [Introduction](#introduction)
2. [SQL vs NoSQL Overview](#sql-vs-nosql-overview)
3. [MongoDB with Mongoose](#mongodb-with-mongoose)
4. [PostgreSQL with pg Driver](#postgresql-with-pg-driver)
5. [PostgreSQL with Sequelize ORM](#postgresql-with-sequelize-orm)
6. [CRUD Operations](#crud-operations)
7. [Query Building](#query-building)
8. [Transactions](#transactions)
9. [Connection Pooling](#connection-pooling)
10. [ORMs vs Query Builders](#orms-vs-query-builders)
11. [Worked Examples](#worked-examples)
12. [Exercises](#exercises)
13. [Testing & Verification](#testing--verification)
14. [Best Practices](#best-practices)
15. [Common Pitfalls](#common-pitfalls)
16. [Performance Considerations](#performance-considerations)
17. [Summary & Next Steps](#summary--next-steps)
18. [References](#references)

---

## Introduction

Database integration is a critical component of backend development. Choosing the right database and implementing efficient data access patterns can make or break your application's performance and scalability.

**Why Database Integration Matters:**

- **Data Persistence:** Store and retrieve application data reliably
- **Performance:** Optimize queries for fast response times
- **Scalability:** Handle growing data volumes efficiently
- **Data Integrity:** Maintain consistency with transactions
- **Flexibility:** Choose the right tool for your data model

**Real-World Applications:**

- **E-commerce:** Product catalogs, orders, inventory management
- **Social Media:** User profiles, posts, relationships, feeds
- **Analytics:** Time-series data, metrics, reporting
- **Content Management:** Articles, media, metadata
- **Financial Systems:** Transactions, accounts, audit trails

---

## SQL vs NoSQL Overview

### Understanding the Fundamental Differences

```javascript
/**
 * SQL vs NoSQL: Key Characteristics
 */

// SQL Databases (PostgreSQL, MySQL, SQLite)
const sqlCharacteristics = {
  structure: 'Relational tables with schemas',
  schema: 'Fixed schema, must define upfront',
  scalability: 'Vertical (more powerful servers)',
  transactions: 'ACID compliant',
  queries: 'SQL language',
  relationships: 'Foreign keys, joins',
  useCase: 'Complex queries, strict consistency',
  examples: ['PostgreSQL', 'MySQL', 'SQLite', 'Oracle']
};

// NoSQL Databases (MongoDB, Redis, Cassandra)
const noSQLCharacteristics = {
  structure: 'Documents, key-value, graph, or column',
  schema: 'Flexible schema, evolve over time',
  scalability: 'Horizontal (more servers)',
  transactions: 'Eventual consistency (some support ACID)',
  queries: 'Database-specific query language',
  relationships: 'Embedded documents or references',
  useCase: 'Flexible data, high throughput',
  examples: ['MongoDB', 'Redis', 'Cassandra', 'DynamoDB']
};
```

### When to Choose SQL

```javascript
/**
 * SQL is ideal for:
 */

// 1. Complex relationships
const sqlExamples = {
  ecommerce: {
    users: 'One user has many orders',
    orders: 'One order has many order items',
    products: 'One product appears in many orders',
    categories: 'Products belong to categories'
  },

  // 2. ACID transactions required
  banking: {
    requirement: 'Transfer money between accounts atomically',
    guarantee: 'Either both operations succeed or both fail'
  },

  // 3. Complex queries with joins
  reporting: {
    query: 'Get total sales by category by region by month',
    requirement: 'Join multiple tables, aggregate data'
  },

  // 4. Data integrity is critical
  healthcare: {
    requirement: 'Strict validation, foreign keys, constraints',
    guarantee: 'No orphaned records, referential integrity'
  }
};
```

### When to Choose NoSQL

```javascript
/**
 * NoSQL is ideal for:
 */

const noSQLExamples = {
  // 1. Flexible, evolving schemas
  contentManagement: {
    articles: 'Different content types with varying fields',
    flexibility: 'Add new fields without migration'
  },

  // 2. High write throughput
  analytics: {
    requirement: 'Millions of events per second',
    solution: 'Horizontal scaling, sharding'
  },

  // 3. Hierarchical data
  socialMedia: {
    structure: 'User posts with nested comments',
    solution: 'Embedded documents, single query'
  },

  // 4. Caching and sessions
  webApps: {
    requirement: 'Fast key-value lookups',
    solution: 'Redis, in-memory storage'
  }
};
```

---

## MongoDB with Mongoose

### Installing and Connecting

```javascript
/**
 * Install: npm install mongoose
 */

import mongoose from 'mongoose';

/**
 * Basic connection
 */
const connectMongoDB = async () => {
  try {
    await mongoose.connect('mongodb://localhost:27017/myapp', {
      // Options for production
      maxPoolSize: 10,
      serverSelectionTimeoutMS: 5000,
      socketTimeoutMS: 45000,
    });

    console.log('MongoDB connected successfully');
  } catch (error) {
    console.error('MongoDB connection error:', error);
    process.exit(1);
  }
};

// Handle connection events
mongoose.connection.on('connected', () => {
  console.log('Mongoose connected to MongoDB');
});

mongoose.connection.on('error', (err) => {
  console.error('Mongoose connection error:', err);
});

mongoose.connection.on('disconnected', () => {
  console.log('Mongoose disconnected');
});

// Graceful shutdown
process.on('SIGINT', async () => {
  await mongoose.connection.close();
  console.log('Mongoose connection closed through app termination');
  process.exit(0);
});
```

### Defining Schemas and Models

```javascript
/**
 * Mongoose schemas define structure and validation
 */

import { Schema, model } from 'mongoose';

// Define schema
const userSchema = new Schema({
  username: {
    type: String,
    required: [true, 'Username is required'],
    unique: true,
    trim: true,
    minlength: [3, 'Username must be at least 3 characters'],
    maxlength: [30, 'Username cannot exceed 30 characters']
  },
  email: {
    type: String,
    required: [true, 'Email is required'],
    unique: true,
    lowercase: true,
    match: [/^\S+@\S+\.\S+$/, 'Please enter a valid email']
  },
  password: {
    type: String,
    required: [true, 'Password is required'],
    minlength: [8, 'Password must be at least 8 characters']
  },
  profile: {
    firstName: String,
    lastName: String,
    age: {
      type: Number,
      min: [0, 'Age cannot be negative'],
      max: [150, 'Age seems invalid']
    },
    bio: {
      type: String,
      maxlength: [500, 'Bio cannot exceed 500 characters']
    }
  },
  roles: {
    type: [String],
    enum: ['user', 'admin', 'moderator'],
    default: ['user']
  },
  isActive: {
    type: Boolean,
    default: true
  },
  lastLogin: Date,
  createdAt: {
    type: Date,
    default: Date.now
  },
  updatedAt: {
    type: Date,
    default: Date.now
  }
}, {
  timestamps: true, // Automatically manage createdAt/updatedAt
  collection: 'users' // Explicit collection name
});

// Add indexes for performance
userSchema.index({ email: 1 });
userSchema.index({ username: 1 });
userSchema.index({ createdAt: -1 });

// Add virtual properties
userSchema.virtual('fullName').get(function() {
  return `${this.profile.firstName} ${this.profile.lastName}`;
});

// Add instance methods
userSchema.methods.comparePassword = async function(candidatePassword) {
  // Would use bcrypt in production
  return candidatePassword === this.password;
};

// Add static methods
userSchema.statics.findByEmail = function(email) {
  return this.findOne({ email: email.toLowerCase() });
};

// Pre-save middleware
userSchema.pre('save', function(next) {
  this.updatedAt = new Date();
  next();
});

// Create model
const User = model('User', userSchema);

export default User;
```

### Relationships in MongoDB

```javascript
/**
 * MongoDB relationships: Embedded vs Referenced
 */

// Embedded documents (for one-to-few)
const blogPostSchema = new Schema({
  title: String,
  content: String,
  author: {
    type: Schema.Types.ObjectId,
    ref: 'User',
    required: true
  },
  comments: [{
    text: String,
    author: {
      type: Schema.Types.ObjectId,
      ref: 'User'
    },
    createdAt: {
      type: Date,
      default: Date.now
    }
  }],
  tags: [String],
  createdAt: {
    type: Date,
    default: Date.now
  }
});

const BlogPost = model('BlogPost', blogPostSchema);

// Referenced documents (for one-to-many, many-to-many)
const orderSchema = new Schema({
  user: {
    type: Schema.Types.ObjectId,
    ref: 'User',
    required: true
  },
  items: [{
    product: {
      type: Schema.Types.ObjectId,
      ref: 'Product',
      required: true
    },
    quantity: {
      type: Number,
      required: true,
      min: 1
    },
    price: Number
  }],
  total: Number,
  status: {
    type: String,
    enum: ['pending', 'processing', 'shipped', 'delivered'],
    default: 'pending'
  },
  createdAt: {
    type: Date,
    default: Date.now
  }
});

const Order = model('Order', orderSchema);
```

---

## PostgreSQL with pg Driver

### Installing and Connecting

```javascript
/**
 * Install: npm install pg
 */

import pkg from 'pg';
const { Pool, Client } = pkg;

/**
 * Using Pool (recommended for web apps)
 */
const pool = new Pool({
  host: 'localhost',
  port: 5432,
  database: 'myapp',
  user: 'postgres',
  password: 'password',
  max: 20, // Maximum number of clients
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

// Test connection
pool.on('connect', () => {
  console.log('PostgreSQL pool connected');
});

pool.on('error', (err) => {
  console.error('Unexpected PostgreSQL error:', err);
  process.exit(-1);
});

/**
 * Execute query with pool
 */
const queryDatabase = async (text, params) => {
  const start = Date.now();
  try {
    const result = await pool.query(text, params);
    const duration = Date.now() - start;
    console.log('Executed query', { text, duration, rows: result.rowCount });
    return result;
  } catch (error) {
    console.error('Query error:', error);
    throw error;
  }
};

// Example usage
const getUser = async (userId) => {
  const query = 'SELECT * FROM users WHERE id = $1';
  const result = await queryDatabase(query, [userId]);
  return result.rows[0];
};
```

### Creating Tables

```javascript
/**
 * Create database schema
 */

const createTables = async () => {
  const client = await pool.connect();

  try {
    await client.query('BEGIN');

    // Users table
    await client.query(`
      CREATE TABLE IF NOT EXISTS users (
        id SERIAL PRIMARY KEY,
        username VARCHAR(30) UNIQUE NOT NULL,
        email VARCHAR(255) UNIQUE NOT NULL,
        password VARCHAR(255) NOT NULL,
        first_name VARCHAR(50),
        last_name VARCHAR(50),
        is_active BOOLEAN DEFAULT TRUE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);

    // Posts table
    await client.query(`
      CREATE TABLE IF NOT EXISTS posts (
        id SERIAL PRIMARY KEY,
        title VARCHAR(255) NOT NULL,
        content TEXT,
        author_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
        published BOOLEAN DEFAULT FALSE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);

    // Comments table
    await client.query(`
      CREATE TABLE IF NOT EXISTS comments (
        id SERIAL PRIMARY KEY,
        post_id INTEGER REFERENCES posts(id) ON DELETE CASCADE,
        author_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
        content TEXT NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);

    // Create indexes
    await client.query(`
      CREATE INDEX IF NOT EXISTS idx_posts_author
      ON posts(author_id)
    `);

    await client.query(`
      CREATE INDEX IF NOT EXISTS idx_comments_post
      ON comments(post_id)
    `);

    await client.query('COMMIT');
    console.log('Tables created successfully');
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('Error creating tables:', error);
    throw error;
  } finally {
    client.release();
  }
};
```

### Prepared Statements

```javascript
/**
 * Prepared statements prevent SQL injection
 */

const userRepository = {
  // Create user with parameterized query
  create: async (userData) => {
    const query = `
      INSERT INTO users (username, email, password, first_name, last_name)
      VALUES ($1, $2, $3, $4, $5)
      RETURNING *
    `;

    const values = [
      userData.username,
      userData.email,
      userData.password,
      userData.firstName,
      userData.lastName
    ];

    const result = await pool.query(query, values);
    return result.rows[0];
  },

  // Find by email
  findByEmail: async (email) => {
    const query = 'SELECT * FROM users WHERE email = $1';
    const result = await pool.query(query, [email]);
    return result.rows[0];
  },

  // Update user
  update: async (userId, updates) => {
    const query = `
      UPDATE users
      SET username = $1, first_name = $2, last_name = $3, updated_at = NOW()
      WHERE id = $4
      RETURNING *
    `;

    const values = [
      updates.username,
      updates.firstName,
      updates.lastName,
      userId
    ];

    const result = await pool.query(query, values);
    return result.rows[0];
  },

  // Delete user
  delete: async (userId) => {
    const query = 'DELETE FROM users WHERE id = $1';
    await pool.query(query, [userId]);
  }
};
```

---

## PostgreSQL with Sequelize ORM

### Setup and Connection

```javascript
/**
 * Install: npm install sequelize pg pg-hstore
 */

import { Sequelize, DataTypes, Model } from 'sequelize';

/**
 * Initialize Sequelize
 */
const sequelize = new Sequelize('myapp', 'postgres', 'password', {
  host: 'localhost',
  dialect: 'postgres',
  logging: console.log, // Set to false in production
  pool: {
    max: 5,
    min: 0,
    acquire: 30000,
    idle: 10000
  }
});

// Test connection
const testConnection = async () => {
  try {
    await sequelize.authenticate();
    console.log('Sequelize connection established successfully');
  } catch (error) {
    console.error('Unable to connect to database:', error);
  }
};
```

### Defining Models

```javascript
/**
 * Define Sequelize models
 */

class User extends Model {}

User.init({
  id: {
    type: DataTypes.INTEGER,
    primaryKey: true,
    autoIncrement: true
  },
  username: {
    type: DataTypes.STRING(30),
    allowNull: false,
    unique: true,
    validate: {
      len: [3, 30]
    }
  },
  email: {
    type: DataTypes.STRING(255),
    allowNull: false,
    unique: true,
    validate: {
      isEmail: true
    }
  },
  password: {
    type: DataTypes.STRING(255),
    allowNull: false,
    validate: {
      len: [8, 100]
    }
  },
  firstName: {
    type: DataTypes.STRING(50),
    field: 'first_name'
  },
  lastName: {
    type: DataTypes.STRING(50),
    field: 'last_name'
  },
  isActive: {
    type: DataTypes.BOOLEAN,
    defaultValue: true,
    field: 'is_active'
  }
}, {
  sequelize,
  modelName: 'User',
  tableName: 'users',
  timestamps: true,
  underscored: true,
  createdAt: 'created_at',
  updatedAt: 'updated_at'
});

// Instance methods
User.prototype.getFullName = function() {
  return `${this.firstName} ${this.lastName}`;
};

// Class methods
User.findByEmail = function(email) {
  return this.findOne({ where: { email } });
};

/**
 * Define Post model
 */
class Post extends Model {}

Post.init({
  id: {
    type: DataTypes.INTEGER,
    primaryKey: true,
    autoIncrement: true
  },
  title: {
    type: DataTypes.STRING(255),
    allowNull: false
  },
  content: {
    type: DataTypes.TEXT
  },
  published: {
    type: DataTypes.BOOLEAN,
    defaultValue: false
  },
  authorId: {
    type: DataTypes.INTEGER,
    allowNull: false,
    field: 'author_id',
    references: {
      model: 'users',
      key: 'id'
    }
  }
}, {
  sequelize,
  modelName: 'Post',
  tableName: 'posts',
  timestamps: true,
  underscored: true
});
```

### Associations

```javascript
/**
 * Define relationships between models
 */

// One-to-Many: User has many Posts
User.hasMany(Post, {
  foreignKey: 'authorId',
  as: 'posts'
});

Post.belongsTo(User, {
  foreignKey: 'authorId',
  as: 'author'
});

// Many-to-Many: Posts and Tags
class Tag extends Model {}

Tag.init({
  name: {
    type: DataTypes.STRING(50),
    allowNull: false,
    unique: true
  }
}, {
  sequelize,
  modelName: 'Tag',
  tableName: 'tags',
  timestamps: true
});

// Junction table
class PostTag extends Model {}

PostTag.init({}, {
  sequelize,
  modelName: 'PostTag',
  tableName: 'post_tags',
  timestamps: false
});

Post.belongsToMany(Tag, {
  through: PostTag,
  foreignKey: 'postId',
  as: 'tags'
});

Tag.belongsToMany(Post, {
  through: PostTag,
  foreignKey: 'tagId',
  as: 'posts'
});

/**
 * Sync models with database
 */
const syncDatabase = async () => {
  try {
    await sequelize.sync({ force: false }); // Set to true to drop tables
    console.log('Database synced successfully');
  } catch (error) {
    console.error('Error syncing database:', error);
  }
};
```

---

## CRUD Operations

### MongoDB CRUD with Mongoose

```javascript
/**
 * Complete CRUD operations with Mongoose
 */

class UserService {
  // CREATE
  static async createUser(userData) {
    try {
      const user = new User(userData);
      await user.save();
      return user;
    } catch (error) {
      if (error.code === 11000) {
        throw new Error('User already exists');
      }
      throw error;
    }
  }

  // READ - Single
  static async getUserById(userId) {
    const user = await User.findById(userId);
    if (!user) {
      throw new Error('User not found');
    }
    return user;
  }

  // READ - Multiple with filtering
  static async getUsers(filters = {}, options = {}) {
    const {
      page = 1,
      limit = 10,
      sortBy = 'createdAt',
      sortOrder = 'desc'
    } = options;

    const skip = (page - 1) * limit;
    const sort = { [sortBy]: sortOrder === 'asc' ? 1 : -1 };

    const users = await User
      .find(filters)
      .sort(sort)
      .skip(skip)
      .limit(limit)
      .select('-password'); // Exclude password

    const total = await User.countDocuments(filters);

    return {
      users,
      pagination: {
        page,
        limit,
        total,
        pages: Math.ceil(total / limit)
      }
    };
  }

  // UPDATE
  static async updateUser(userId, updates) {
    const user = await User.findByIdAndUpdate(
      userId,
      { $set: updates },
      { new: true, runValidators: true }
    );

    if (!user) {
      throw new Error('User not found');
    }

    return user;
  }

  // DELETE
  static async deleteUser(userId) {
    const user = await User.findByIdAndDelete(userId);
    if (!user) {
      throw new Error('User not found');
    }
    return user;
  }

  // SEARCH
  static async searchUsers(searchTerm) {
    return await User.find({
      $or: [
        { username: { $regex: searchTerm, $options: 'i' } },
        { email: { $regex: searchTerm, $options: 'i' } },
        { 'profile.firstName': { $regex: searchTerm, $options: 'i' } },
        { 'profile.lastName': { $regex: searchTerm, $options: 'i' } }
      ]
    }).select('-password');
  }
}
```

### PostgreSQL CRUD with Sequelize

```javascript
/**
 * Complete CRUD operations with Sequelize
 */

class UserServiceSQL {
  // CREATE
  static async createUser(userData) {
    try {
      const user = await User.create(userData);
      return user;
    } catch (error) {
      if (error.name === 'SequelizeUniqueConstraintError') {
        throw new Error('User already exists');
      }
      throw error;
    }
  }

  // READ - Single
  static async getUserById(userId) {
    const user = await User.findByPk(userId, {
      attributes: { exclude: ['password'] }
    });

    if (!user) {
      throw new Error('User not found');
    }

    return user;
  }

  // READ - Multiple with filtering
  static async getUsers(filters = {}, options = {}) {
    const {
      page = 1,
      limit = 10,
      sortBy = 'createdAt',
      sortOrder = 'DESC'
    } = options;

    const offset = (page - 1) * limit;

    const { count, rows } = await User.findAndCountAll({
      where: filters,
      attributes: { exclude: ['password'] },
      order: [[sortBy, sortOrder]],
      limit,
      offset
    });

    return {
      users: rows,
      pagination: {
        page,
        limit,
        total: count,
        pages: Math.ceil(count / limit)
      }
    };
  }

  // UPDATE
  static async updateUser(userId, updates) {
    const user = await User.findByPk(userId);

    if (!user) {
      throw new Error('User not found');
    }

    await user.update(updates);
    return user;
  }

  // DELETE
  static async deleteUser(userId) {
    const deleted = await User.destroy({
      where: { id: userId }
    });

    if (!deleted) {
      throw new Error('User not found');
    }

    return { deleted: true };
  }

  // SEARCH
  static async searchUsers(searchTerm) {
    const { Op } = require('sequelize');

    return await User.findAll({
      where: {
        [Op.or]: [
          { username: { [Op.iLike]: `%${searchTerm}%` } },
          { email: { [Op.iLike]: `%${searchTerm}%` } },
          { firstName: { [Op.iLike]: `%${searchTerm}%` } },
          { lastName: { [Op.iLike]: `%${searchTerm}%` } }
        ]
      },
      attributes: { exclude: ['password'] }
    });
  }
}
```

---

## Query Building

### Complex MongoDB Queries

```javascript
/**
 * Advanced querying with Mongoose
 */

class PostQueries {
  // Aggregation pipeline
  static async getPostStatsByAuthor() {
    return await BlogPost.aggregate([
      {
        $group: {
          _id: '$author',
          totalPosts: { $sum: 1 },
          avgComments: { $avg: { $size: '$comments' } },
          tags: { $addToSet: '$tags' }
        }
      },
      {
        $lookup: {
          from: 'users',
          localField: '_id',
          foreignField: '_id',
          as: 'authorInfo'
        }
      },
      {
        $unwind: '$authorInfo'
      },
      {
        $project: {
          author: '$authorInfo.username',
          totalPosts: 1,
          avgComments: 1,
          uniqueTags: { $size: { $reduce: {
            input: '$tags',
            initialValue: [],
            in: { $setUnion: ['$$value', '$$this'] }
          }}}
        }
      },
      {
        $sort: { totalPosts: -1 }
      }
    ]);
  }

  // Population with nested paths
  static async getPostsWithAuthors(page = 1, limit = 10) {
    return await BlogPost
      .find()
      .populate({
        path: 'author',
        select: 'username profile.firstName profile.lastName'
      })
      .populate({
        path: 'comments.author',
        select: 'username'
      })
      .sort({ createdAt: -1 })
      .skip((page - 1) * limit)
      .limit(limit)
      .lean(); // Convert to plain JavaScript objects
  }

  // Complex filtering
  static async searchPosts(criteria) {
    const query = {};

    if (criteria.tags && criteria.tags.length > 0) {
      query.tags = { $all: criteria.tags };
    }

    if (criteria.dateFrom || criteria.dateTo) {
      query.createdAt = {};
      if (criteria.dateFrom) {
        query.createdAt.$gte = new Date(criteria.dateFrom);
      }
      if (criteria.dateTo) {
        query.createdAt.$lte = new Date(criteria.dateTo);
      }
    }

    if (criteria.search) {
      query.$text = { $search: criteria.search };
    }

    return await BlogPost
      .find(query)
      .select('title content author createdAt')
      .sort({ createdAt: -1 });
  }
}
```

### Complex PostgreSQL Queries

```javascript
/**
 * Advanced querying with Sequelize
 */

import { Op } from 'sequelize';

class PostQueriesSQL {
  // Join queries
  static async getPostsWithAuthors(page = 1, limit = 10) {
    const offset = (page - 1) * limit;

    return await Post.findAndCountAll({
      include: [{
        model: User,
        as: 'author',
        attributes: ['id', 'username', 'firstName', 'lastName']
      }],
      order: [['createdAt', 'DESC']],
      limit,
      offset
    });
  }

  // Complex where clauses
  static async searchPosts(criteria) {
    const where = {};

    if (criteria.authorId) {
      where.authorId = criteria.authorId;
    }

    if (criteria.published !== undefined) {
      where.published = criteria.published;
    }

    if (criteria.search) {
      where[Op.or] = [
        { title: { [Op.iLike]: `%${criteria.search}%` } },
        { content: { [Op.iLike]: `%${criteria.search}%` } }
      ];
    }

    if (criteria.dateFrom || criteria.dateTo) {
      where.createdAt = {};
      if (criteria.dateFrom) {
        where.createdAt[Op.gte] = new Date(criteria.dateFrom);
      }
      if (criteria.dateTo) {
        where.createdAt[Op.lte] = new Date(criteria.dateTo);
      }
    }

    return await Post.findAll({
      where,
      include: [{
        model: User,
        as: 'author',
        attributes: ['username']
      }],
      order: [['createdAt', 'DESC']]
    });
  }

  // Raw SQL queries when needed
  static async getPostStatistics() {
    const [results] = await sequelize.query(`
      SELECT
        u.username,
        COUNT(p.id) as total_posts,
        COUNT(CASE WHEN p.published = true THEN 1 END) as published_posts,
        MAX(p.created_at) as last_post_date
      FROM users u
      LEFT JOIN posts p ON u.id = p.author_id
      GROUP BY u.id, u.username
      HAVING COUNT(p.id) > 0
      ORDER BY total_posts DESC
    `);

    return results;
  }

  // Subqueries
  static async getActiveAuthors() {
    return await User.findAll({
      where: {
        id: {
          [Op.in]: sequelize.literal(`
            (SELECT DISTINCT author_id FROM posts
             WHERE created_at > NOW() - INTERVAL '30 days')
          `)
        }
      }
    });
  }
}
```

---

## Transactions

### MongoDB Transactions

```javascript
/**
 * MongoDB transactions (requires replica set)
 */

const transferFunds = async (fromAccountId, toAccountId, amount) => {
  const session = await mongoose.startSession();
  session.startTransaction();

  try {
    // Deduct from sender
    const fromAccount = await Account.findByIdAndUpdate(
      fromAccountId,
      { $inc: { balance: -amount } },
      { session, new: true }
    );

    if (fromAccount.balance < 0) {
      throw new Error('Insufficient funds');
    }

    // Add to receiver
    await Account.findByIdAndUpdate(
      toAccountId,
      { $inc: { balance: amount } },
      { session, new: true }
    );

    // Create transaction record
    await Transaction.create([{
      from: fromAccountId,
      to: toAccountId,
      amount,
      type: 'transfer',
      timestamp: new Date()
    }], { session });

    // Commit transaction
    await session.commitTransaction();
    console.log('Transaction successful');

    return { success: true };
  } catch (error) {
    // Rollback on error
    await session.abortTransaction();
    console.error('Transaction failed:', error);
    throw error;
  } finally {
    session.endSession();
  }
};
```

### PostgreSQL Transactions

```javascript
/**
 * PostgreSQL transactions with pg
 */

const transferFundsSQL = async (fromAccountId, toAccountId, amount) => {
  const client = await pool.connect();

  try {
    await client.query('BEGIN');

    // Deduct from sender
    const deductResult = await client.query(
      'UPDATE accounts SET balance = balance - $1 WHERE id = $2 RETURNING balance',
      [amount, fromAccountId]
    );

    if (deductResult.rows[0].balance < 0) {
      throw new Error('Insufficient funds');
    }

    // Add to receiver
    await client.query(
      'UPDATE accounts SET balance = balance + $1 WHERE id = $2',
      [amount, toAccountId]
    );

    // Create transaction record
    await client.query(
      `INSERT INTO transactions (from_account, to_account, amount, type)
       VALUES ($1, $2, $3, 'transfer')`,
      [fromAccountId, toAccountId, amount]
    );

    await client.query('COMMIT');
    console.log('Transaction successful');

    return { success: true };
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('Transaction failed:', error);
    throw error;
  } finally {
    client.release();
  }
};

/**
 * Sequelize transactions
 */

const transferFundsSequelize = async (fromAccountId, toAccountId, amount) => {
  const t = await sequelize.transaction();

  try {
    // Deduct from sender
    const fromAccount = await Account.findByPk(fromAccountId, {
      transaction: t,
      lock: t.LOCK.UPDATE // Row-level lock
    });

    if (fromAccount.balance < amount) {
      throw new Error('Insufficient funds');
    }

    fromAccount.balance -= amount;
    await fromAccount.save({ transaction: t });

    // Add to receiver
    const toAccount = await Account.findByPk(toAccountId, {
      transaction: t,
      lock: t.LOCK.UPDATE
    });

    toAccount.balance += amount;
    await toAccount.save({ transaction: t });

    // Create transaction record
    await TransactionModel.create({
      fromAccount: fromAccountId,
      toAccount: toAccountId,
      amount,
      type: 'transfer'
    }, { transaction: t });

    await t.commit();
    return { success: true };
  } catch (error) {
    await t.rollback();
    throw error;
  }
};
```

---

## Connection Pooling

### Configuring Connection Pools

```javascript
/**
 * PostgreSQL connection pooling
 */

const productionPool = new Pool({
  host: process.env.DB_HOST,
  port: process.env.DB_PORT,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,

  // Pool configuration
  max: 20, // Maximum connections
  min: 5,  // Minimum connections
  idleTimeoutMillis: 30000, // Close idle connections after 30s
  connectionTimeoutMillis: 2000, // Fail fast if can't connect

  // SSL for production
  ssl: process.env.NODE_ENV === 'production' ? {
    rejectUnauthorized: false
  } : false
});

/**
 * Monitor pool health
 */
const monitorPool = () => {
  setInterval(() => {
    console.log('Pool stats:', {
      total: productionPool.totalCount,
      idle: productionPool.idleCount,
      waiting: productionPool.waitingCount
    });
  }, 60000); // Every minute
};

/**
 * MongoDB connection pooling
 */

const mongooseOptions = {
  maxPoolSize: 10,
  minPoolSize: 5,
  maxIdleTimeMS: 30000,
  serverSelectionTimeoutMS: 5000,
  socketTimeoutMS: 45000,
  family: 4 // Use IPv4
};

await mongoose.connect(process.env.MONGO_URI, mongooseOptions);

/**
 * Sequelize connection pooling
 */

const sequelizeProduction = new Sequelize(
  process.env.DB_NAME,
  process.env.DB_USER,
  process.env.DB_PASSWORD,
  {
    host: process.env.DB_HOST,
    dialect: 'postgres',
    logging: false,

    pool: {
      max: 10,
      min: 2,
      acquire: 30000,
      idle: 10000
    },

    dialectOptions: {
      ssl: process.env.NODE_ENV === 'production' ? {
        require: true,
        rejectUnauthorized: false
      } : false
    }
  }
);
```

---

## ORMs vs Query Builders

### Comparison Table

```javascript
/**
 * ORMs vs Query Builders Decision Matrix
 */

const comparison = {
  ORM: {
    examples: ['Sequelize', 'TypeORM', 'Prisma'],

    pros: [
      'Abstract away SQL',
      'Model-based approach',
      'Built-in validation',
      'Migrations included',
      'Type safety (TypeScript)',
      'Relationships handled automatically'
    ],

    cons: [
      'Learning curve',
      'Less control over SQL',
      'Performance overhead',
      'Complex queries can be difficult',
      'Bloated for simple operations'
    ],

    bestFor: [
      'Complex applications',
      'Team with limited SQL knowledge',
      'Rapid prototyping',
      'Type safety requirements'
    ]
  },

  QueryBuilder: {
    examples: ['Knex.js', 'Kysely'],

    pros: [
      'More control over SQL',
      'Better performance',
      'Easier to optimize',
      'Flexible query building',
      'Lighter weight'
    ],

    cons: [
      'More boilerplate',
      'Manual validation',
      'No built-in models',
      'Relationships manual',
      'More SQL knowledge needed'
    ],

    bestFor: [
      'Performance-critical apps',
      'Complex custom queries',
      'Team with strong SQL skills',
      'Microservices'
    ]
  },

  RawSQL: {
    examples: ['pg', 'mysql2'],

    pros: [
      'Maximum control',
      'Best performance',
      'No abstraction overhead',
      'Use all DB features'
    ],

    cons: [
      'SQL injection risk',
      'More code to write',
      'No type safety',
      'Manual everything'
    ],

    bestFor: [
      'Simple applications',
      'Maximum performance needed',
      'SQL experts',
      'Specific DB features required'
    ]
  }
};
```

### Example: Same Query, Different Approaches

```javascript
/**
 * Get users with their post count, different approaches
 */

// 1. Raw SQL with pg
const rawSQL = async () => {
  const result = await pool.query(`
    SELECT
      u.id,
      u.username,
      u.email,
      COUNT(p.id) as post_count
    FROM users u
    LEFT JOIN posts p ON u.id = p.author_id
    WHERE u.is_active = true
    GROUP BY u.id
    HAVING COUNT(p.id) > 5
    ORDER BY post_count DESC
    LIMIT 10
  `);

  return result.rows;
};

// 2. Query Builder with Knex
import knex from 'knex';

const db = knex({
  client: 'pg',
  connection: process.env.DATABASE_URL
});

const queryBuilder = async () => {
  return await db('users as u')
    .select('u.id', 'u.username', 'u.email')
    .count('p.id as post_count')
    .leftJoin('posts as p', 'u.id', 'p.author_id')
    .where('u.is_active', true)
    .groupBy('u.id')
    .having(db.raw('COUNT(p.id) > ?', [5]))
    .orderBy('post_count', 'desc')
    .limit(10);
};

// 3. ORM with Sequelize
const ormSequelize = async () => {
  return await User.findAll({
    attributes: [
      'id',
      'username',
      'email',
      [sequelize.fn('COUNT', sequelize.col('posts.id')), 'post_count']
    ],
    include: [{
      model: Post,
      as: 'posts',
      attributes: []
    }],
    where: {
      isActive: true
    },
    group: ['User.id'],
    having: sequelize.where(
      sequelize.fn('COUNT', sequelize.col('posts.id')),
      Op.gt,
      5
    ),
    order: [[sequelize.literal('post_count'), 'DESC']],
    limit: 10,
    subQuery: false
  });
};
```

---

## Worked Examples

### Example 1: Complete Blog API with MongoDB

```javascript
/**
 * Worked Example 1: Blog API with MongoDB/Mongoose
 *
 * Demonstrates:
 * - Model definitions
 * - CRUD operations
 * - Relationships
 * - Error handling
 */

import express from 'express';
import mongoose from 'mongoose';

// Models
const userSchema = new mongoose.Schema({
  username: { type: String, required: true, unique: true },
  email: { type: String, required: true, unique: true },
  passwordHash: { type: String, required: true }
}, { timestamps: true });

const postSchema = new mongoose.Schema({
  title: { type: String, required: true },
  content: { type: String, required: true },
  author: {
    type: mongoose.Schema.Types.ObjectId,
    ref: 'User',
    required: true
  },
  tags: [String],
  comments: [{
    author: { type: mongoose.Schema.Types.ObjectId, ref: 'User' },
    content: String,
    createdAt: { type: Date, default: Date.now }
  }],
  published: { type: Boolean, default: false }
}, { timestamps: true });

const User = mongoose.model('User', userSchema);
const Post = mongoose.model('Post', postSchema);

// API Routes
const app = express();
app.use(express.json());

// Create post
app.post('/api/posts', async (req, res) => {
  try {
    const { title, content, authorId, tags } = req.body;

    const post = new Post({
      title,
      content,
      author: authorId,
      tags
    });

    await post.save();
    await post.populate('author', 'username email');

    res.status(201).json({ success: true, post });
  } catch (error) {
    res.status(400).json({ success: false, error: error.message });
  }
});

// Get posts with pagination
app.get('/api/posts', async (req, res) => {
  try {
    const page = parseInt(req.query.page) || 1;
    const limit = parseInt(req.query.limit) || 10;
    const skip = (page - 1) * limit;

    const posts = await Post
      .find({ published: true })
      .populate('author', 'username')
      .populate('comments.author', 'username')
      .sort({ createdAt: -1 })
      .skip(skip)
      .limit(limit);

    const total = await Post.countDocuments({ published: true });

    res.json({
      success: true,
      posts,
      pagination: {
        page,
        limit,
        total,
        pages: Math.ceil(total / limit)
      }
    });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});

// Add comment
app.post('/api/posts/:id/comments', async (req, res) => {
  try {
    const { content, authorId } = req.body;

    const post = await Post.findByIdAndUpdate(
      req.params.id,
      {
        $push: {
          comments: {
            author: authorId,
            content,
            createdAt: new Date()
          }
        }
      },
      { new: true }
    ).populate('comments.author', 'username');

    if (!post) {
      return res.status(404).json({ success: false, error: 'Post not found' });
    }

    res.json({ success: true, post });
  } catch (error) {
    res.status(400).json({ success: false, error: error.message });
  }
});

// Search posts
app.get('/api/posts/search', async (req, res) => {
  try {
    const { q, tags } = req.query;

    const query = { published: true };

    if (q) {
      query.$or = [
        { title: { $regex: q, $options: 'i' } },
        { content: { $regex: q, $options: 'i' } }
      ];
    }

    if (tags) {
      query.tags = { $in: tags.split(',') };
    }

    const posts = await Post
      .find(query)
      .populate('author', 'username')
      .sort({ createdAt: -1 })
      .limit(20);

    res.json({ success: true, posts });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});
```

### Example 2: E-commerce Order System with PostgreSQL

```javascript
/**
 * Worked Example 2: E-commerce with PostgreSQL/Sequelize
 *
 * Demonstrates:
 * - Complex relationships
 * - Transactions
 * - Inventory management
 * - Order processing
 */

import { Sequelize, DataTypes, Model } from 'sequelize';

const sequelize = new Sequelize(process.env.DATABASE_URL);

// Product Model
class Product extends Model {}
Product.init({
  name: { type: DataTypes.STRING, allowNull: false },
  price: { type: DataTypes.DECIMAL(10, 2), allowNull: false },
  stock: { type: DataTypes.INTEGER, defaultValue: 0 },
  sku: { type: DataTypes.STRING, unique: true }
}, { sequelize, modelName: 'Product' });

// Order Model
class Order extends Model {}
Order.init({
  userId: { type: DataTypes.INTEGER, allowNull: false },
  status: {
    type: DataTypes.ENUM('pending', 'processing', 'shipped', 'delivered', 'cancelled'),
    defaultValue: 'pending'
  },
  total: { type: DataTypes.DECIMAL(10, 2), allowNull: false }
}, { sequelize, modelName: 'Order' });

// OrderItem Model
class OrderItem extends Model {}
OrderItem.init({
  orderId: { type: DataTypes.INTEGER, allowNull: false },
  productId: { type: DataTypes.INTEGER, allowNull: false },
  quantity: { type: DataTypes.INTEGER, allowNull: false },
  price: { type: DataTypes.DECIMAL(10, 2), allowNull: false }
}, { sequelize, modelName: 'OrderItem' });

// Relationships
Order.hasMany(OrderItem, { foreignKey: 'orderId', as: 'items' });
OrderItem.belongsTo(Product, { foreignKey: 'productId' });

// Create order with transaction
const createOrder = async (userId, items) => {
  const t = await sequelize.transaction();

  try {
    let total = 0;

    // Validate stock and calculate total
    for (const item of items) {
      const product = await Product.findByPk(item.productId, {
        transaction: t,
        lock: t.LOCK.UPDATE
      });

      if (!product) {
        throw new Error(`Product ${item.productId} not found`);
      }

      if (product.stock < item.quantity) {
        throw new Error(`Insufficient stock for ${product.name}`);
      }

      total += parseFloat(product.price) * item.quantity;
    }

    // Create order
    const order = await Order.create({
      userId,
      total,
      status: 'pending'
    }, { transaction: t });

    // Create order items and update stock
    for (const item of items) {
      const product = await Product.findByPk(item.productId, {
        transaction: t
      });

      await OrderItem.create({
        orderId: order.id,
        productId: item.productId,
        quantity: item.quantity,
        price: product.price
      }, { transaction: t });

      await product.decrement('stock', {
        by: item.quantity,
        transaction: t
      });
    }

    await t.commit();

    // Fetch complete order
    return await Order.findByPk(order.id, {
      include: [{
        model: OrderItem,
        as: 'items',
        include: [Product]
      }]
    });
  } catch (error) {
    await t.rollback();
    throw error;
  }
};

// Cancel order and restore stock
const cancelOrder = async (orderId) => {
  const t = await sequelize.transaction();

  try {
    const order = await Order.findByPk(orderId, {
      include: [{ model: OrderItem, as: 'items' }],
      transaction: t,
      lock: t.LOCK.UPDATE
    });

    if (!order) {
      throw new Error('Order not found');
    }

    if (order.status !== 'pending') {
      throw new Error('Cannot cancel order in current status');
    }

    // Restore stock
    for (const item of order.items) {
      await Product.increment('stock', {
        by: item.quantity,
        where: { id: item.productId },
        transaction: t
      });
    }

    // Update order status
    order.status = 'cancelled';
    await order.save({ transaction: t });

    await t.commit();
    return order;
  } catch (error) {
    await t.rollback();
    throw error;
  }
};

// Get order statistics
const getOrderStats = async () => {
  const [results] = await sequelize.query(`
    SELECT
      DATE_TRUNC('day', created_at) as date,
      COUNT(*) as total_orders,
      SUM(total) as total_revenue,
      AVG(total) as avg_order_value
    FROM orders
    WHERE status != 'cancelled'
      AND created_at > NOW() - INTERVAL '30 days'
    GROUP BY DATE_TRUNC('day', created_at)
    ORDER BY date DESC
  `);

  return results;
};
```

### Example 3: Data Migration Script

```javascript
/**
 * Worked Example 3: Migrate data from MongoDB to PostgreSQL
 *
 * Demonstrates:
 * - Reading from one database
 * - Writing to another
 * - Data transformation
 * - Error handling
 * - Progress tracking
 */

import mongoose from 'mongoose';
import { Pool } from 'pg';

// Source: MongoDB
const mongoUri = 'mongodb://localhost:27017/sourcedb';
await mongoose.connect(mongoUri);

const MongoUser = mongoose.model('User', new mongoose.Schema({
  username: String,
  email: String,
  profile: {
    firstName: String,
    lastName: String,
    age: Number
  },
  createdAt: Date
}));

// Target: PostgreSQL
const pgPool = new Pool({
  connectionString: 'postgresql://localhost:5432/targetdb'
});

// Create target table
await pgPool.query(`
  CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE,
    email VARCHAR(255) UNIQUE,
    first_name VARCHAR(50),
    last_name VARCHAR(50),
    age INTEGER,
    created_at TIMESTAMP,
    migrated_at TIMESTAMP DEFAULT NOW()
  )
`);

// Migration function
const migrateUsers = async () => {
  const batchSize = 100;
  let page = 0;
  let migrated = 0;
  let errors = 0;

  console.log('Starting migration...');

  while (true) {
    // Fetch batch from MongoDB
    const users = await MongoUser
      .find()
      .skip(page * batchSize)
      .limit(batchSize)
      .lean();

    if (users.length === 0) break;

    // Insert into PostgreSQL
    for (const user of users) {
      try {
        await pgPool.query(
          `INSERT INTO users (username, email, first_name, last_name, age, created_at)
           VALUES ($1, $2, $3, $4, $5, $6)
           ON CONFLICT (email) DO NOTHING`,
          [
            user.username,
            user.email,
            user.profile?.firstName,
            user.profile?.lastName,
            user.profile?.age,
            user.createdAt
          ]
        );
        migrated++;
      } catch (error) {
        console.error(`Error migrating user ${user.email}:`, error.message);
        errors++;
      }
    }

    page++;
    console.log(`Migrated ${migrated} users, ${errors} errors`);
  }

  console.log(`Migration complete! Total: ${migrated}, Errors: ${errors}`);
};

// Run migration
await migrateUsers();

// Cleanup
await mongoose.connection.close();
await pgPool.end();
```

---

## Exercises

### Exercise 1: User Registration System (Easy)

**Problem:** Create a complete user registration system with MongoDB.

```javascript
/**
 * Implement user registration with:
 * - Email validation
 * - Password hashing
 * - Duplicate prevention
 * - Error handling
 */

import mongoose from 'mongoose';
import bcrypt from 'bcrypt';

// Define User model
const userSchema = new mongoose.Schema({
  // Your schema here
});

// Implement registration function
async function registerUser(userData) {
  // Your code here
}

// Test
const newUser = await registerUser({
  email: 'user@example.com',
  password: 'SecurePass123',
  username: 'johndoe'
});
```

**Solution:** See `solutions/exercise1_database.js`

---

### Exercise 2: Query Optimization (Medium)

**Problem:** Optimize slow queries with proper indexing.

```javascript
/**
 * Given a slow query, add appropriate indexes
 * and measure performance improvement
 */

// Slow query
const findRecentActiveUsers = async () => {
  return await User.find({
    isActive: true,
    lastLogin: { $gte: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000) }
  }).sort({ lastLogin: -1 });
};

// Add indexes and optimize
// Your solution here
```

**Solution:** See `solutions/exercise2_database.js`

---

### Exercise 3: Shopping Cart with Transactions (Medium)

**Problem:** Implement a shopping cart checkout with proper transaction handling.

```javascript
/**
 * Implement checkout that:
 * - Validates stock availability
 * - Deducts inventory
 * - Creates order
 * - Rolls back on any error
 */

async function checkoutCart(userId, cartItems) {
  // Your implementation
}
```

**Solution:** See `solutions/exercise3_database.js`

---

### Exercise 4: Complex Aggregation (Hard)

**Problem:** Write an aggregation query to generate a sales report.

```javascript
/**
 * Generate a report showing:
 * - Total sales by product category
 * - Average order value
 * - Top 10 customers by revenue
 * - Monthly revenue trend
 */

async function generateSalesReport(startDate, endDate) {
  // Your aggregation pipeline
}
```

**Solution:** See `solutions/exercise4_database.js`

---

### Exercise 5: Data Validation Layer (Hard)

**Problem:** Create a validation layer for database operations.

```javascript
/**
 * Create a reusable validation system that:
 * - Validates input before database operations
 * - Sanitizes data
 * - Provides detailed error messages
 * - Works with both MongoDB and PostgreSQL
 */

class DatabaseValidator {
  // Your implementation
}
```

**Solution:** See `solutions/exercise5_database.js`

---

## Testing & Verification

```javascript
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import mongoose from 'mongoose';
import { Pool } from 'pg';

describe('Database Integration', () => {
  let mongoConnection;
  let pgPool;

  beforeAll(async () => {
    mongoConnection = await mongoose.connect('mongodb://localhost:27017/test');
    pgPool = new Pool({ connectionString: 'postgresql://localhost/test' });
  });

  afterAll(async () => {
    await mongoose.connection.close();
    await pgPool.end();
  });

  describe('MongoDB Operations', () => {
    it('should create a user', async () => {
      const user = await User.create({
        username: 'testuser',
        email: 'test@example.com',
        password: 'hashedpassword'
      });

      expect(user.username).toBe('testuser');
      expect(user).toHaveProperty('_id');
    });

    it('should prevent duplicate emails', async () => {
      await expect(User.create({
        username: 'testuser2',
        email: 'test@example.com',
        password: 'hashedpassword'
      })).rejects.toThrow();
    });
  });

  describe('PostgreSQL Operations', () => {
    it('should execute parameterized queries', async () => {
      const result = await pgPool.query(
        'SELECT $1::text as message',
        ['Hello, World!']
      );

      expect(result.rows[0].message).toBe('Hello, World!');
    });
  });

  describe('Transactions', () => {
    it('should rollback on error', async () => {
      const session = await mongoose.startSession();
      session.startTransaction();

      try {
        await User.create([{ username: 'tx1', email: 'tx1@test.com' }], { session });
        throw new Error('Forced error');
      } catch (error) {
        await session.abortTransaction();
      } finally {
        session.endSession();
      }

      const user = await User.findOne({ username: 'tx1' });
      expect(user).toBeNull();
    });
  });
});
```

---

## Best Practices

1. **Always use parameterized queries** to prevent SQL injection
2. **Index frequently queried fields** for performance
3. **Use transactions** for operations that must be atomic
4. **Implement connection pooling** for production apps
5. **Handle errors gracefully** with proper error messages
6. **Validate input** before database operations
7. **Use environment variables** for connection strings
8. **Monitor query performance** and optimize slow queries
9. **Implement proper logging** for debugging
10. **Regular backups** and disaster recovery planning

---

## Common Pitfalls

1. **Not closing connections** leads to connection leaks
2. **Missing indexes** causes slow queries
3. **N+1 query problem** when not using joins/populate
4. **Not using transactions** for multi-step operations
5. **Exposing sensitive data** like passwords in queries
6. **Hardcoding credentials** instead of using environment variables
7. **Not handling connection errors** properly
8. **Overusing ORMs** for simple queries
9. **Not validating data** before insertion
10. **Ignoring database constraints** and relying only on application logic

---

## Performance Considerations

### Indexing Strategy

```javascript
/**
 * Effective indexing
 */

// MongoDB indexes
userSchema.index({ email: 1 }); // Single field
userSchema.index({ lastName: 1, firstName: 1 }); // Compound
userSchema.index({ 'profile.bio': 'text' }); // Text search
userSchema.index({ location: '2dsphere' }); // Geospatial

// PostgreSQL indexes
await pool.query('CREATE INDEX idx_users_email ON users(email)');
await pool.query('CREATE INDEX idx_users_name ON users(last_name, first_name)');
await pool.query('CREATE INDEX idx_posts_created ON posts(created_at DESC)');
```

### Query Optimization

```javascript
/**
 * Optimize queries
 */

//  BAD: N+1 problem
const posts = await Post.find();
for (const post of posts) {
  post.author = await User.findById(post.authorId); // N queries!
}

//  GOOD: Use populate/join
const posts = await Post.find().populate('author');

//  BAD: Loading unnecessary fields
const users = await User.find(); // Loads everything including password

//  GOOD: Select only needed fields
const users = await User.find().select('username email');
```

### Caching

```javascript
/**
 * Implement caching for frequently accessed data
 */

import Redis from 'ioredis';
const redis = new Redis();

const getUserWithCache = async (userId) => {
  // Check cache first
  const cached = await redis.get(`user:${userId}`);
  if (cached) {
    return JSON.parse(cached);
  }

  // Fetch from database
  const user = await User.findById(userId);

  // Cache for 1 hour
  await redis.setex(`user:${userId}`, 3600, JSON.stringify(user));

  return user;
};
```

---

## Summary & Next Steps

### Key Takeaways

- Choose the right database type (SQL vs NoSQL) based on your needs
- Use ORMs for rapid development, query builders for performance
- Always implement proper error handling and validation
- Transactions ensure data integrity for multi-step operations
- Connection pooling is essential for production applications
- Index your queries for optimal performance

### Related Topics

- [Authentication and Authorization](./37.Authentication_And_Authorization.md)
- [Performance and Optimization](./40.Performance_And_Optimization.md)
- [Security Best Practices](./41.Security_Best_Practices.md)

### Further Reading

- [MongoDB Documentation](https://docs.mongodb.com/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Mongoose Guide](https://mongoosejs.com/docs/guide.html)
- [Sequelize Documentation](https://sequelize.org/)

---

## References

- MongoDB Official Docs: https://docs.mongodb.com/
- PostgreSQL Manual: https://www.postgresql.org/docs/
- Mongoose Documentation: https://mongoosejs.com/
- Sequelize ORM: https://sequelize.org/
- Node.js pg Library: https://node-postgres.com/

---

**Next Lesson:** [Authentication and Authorization](./37.Authentication_And_Authorization.md)
